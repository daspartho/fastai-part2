{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/daspartho/fastai-part2/blob/main/minibatch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z9WEckAbtJbQ"
   },
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from urllib.request import urlretrieve\n",
    "from fastcore.test import test_close\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "\n",
    "if not path_gz.exists():\n",
    "    urlretrieve(MNIST_URL, path_gz)\n",
    "\n",
    "with gzip.open(path_gz, 'rb') as f: \n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh=50\n",
    "n,m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            nn.Linear(n_in, nh), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nh, n_out),\n",
    "        ]\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross entrophy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    a = x.max(-1)[0]\n",
    "    return a + (x-a.unsqueeze(dim=1)).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "test_close(logsumexp(pred), pred.logsumexp(-1)) # comparing with pytorch's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - logsumexp(x).unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.40, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.14, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0,5],sm_pred[1,0],sm_pred[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.40, -2.37, -2.14], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2],y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(inp, targ):\n",
    "    return - inp[range(targ.shape[0]), targ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "\n",
    "xb = x_train[:bs]\n",
    "yb = y_train[:bs]\n",
    "preds = model(xb)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.28, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = F.cross_entropy\n",
    "loss_fn(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(out, y):\n",
    "    return (out.argmax(dim=1)==y).float().mean()\n",
    "acc(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, accuracy):\n",
    "    print(f'loss: {loss:.2f}, accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08, accuracy: 0.96\n",
      "loss: 0.05, accuracy: 0.98\n",
      "loss: 0.07, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# basic training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, bs+i))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.inference_mode():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad*lr\n",
    "                    l.bias -= l.bias.grad*lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    accuracy = acc(preds, yb)\n",
    "    report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children():\n",
    "    print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, bs+i))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr   \n",
    "                model.zero_grad()                 \n",
    "        accuracy = acc(preds, yb)\n",
    "        report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.12, accuracy: 0.96\n",
      "loss: 0.09, accuracy: 0.96\n",
      "loss: 0.08, accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith('_'):\n",
    "            self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True), 'relu': ReLU()}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = MyModule(m, nh, 10)\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in module.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers=layers\n",
    "        for i, l in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{i}\", l)\n",
    "    def forward(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]\n",
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13, accuracy: 0.96\n",
      "loss: 0.10, accuracy: 0.96\n",
      "loss: 0.05, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.07, accuracy: 0.98\n",
      "loss: 0.04, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self. params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr   \n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.zero_()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.29, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "opt = Optimizer(model.parameters())\n",
    "loss_fn(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15, accuracy: 0.94\n",
      "loss: 0.08, accuracy: 0.96\n",
      "loss: 0.06, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, bs+i))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()               \n",
    "    accuracy = acc(preds, yb)\n",
    "    report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.28, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "opt = optim.SGD(model.parameters(), lr=lr) \n",
    "loss_fn(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.16, accuracy: 0.96\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.05, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, bs+i))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()               \n",
    "    accuracy = acc(preds, yb)\n",
    "    report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([5]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)\n",
    "xb, yb = train_ds[:5]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "opt = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14, accuracy: 0.92\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.07, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, bs+i))\n",
    "        xb, yb = train_ds[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()               \n",
    "    accuracy = acc(preds, yb)\n",
    "    report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            s = slice(i, min(len(self.ds), self.bs+i))\n",
    "            yield self.ds[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()               \n",
    "        accuracy = acc(preds, yb)\n",
    "        report(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10, accuracy: 0.98\n",
      "loss: 0.07, accuracy: 0.96\n",
      "loss: 0.07, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "ss = Sampler(train_ds)\n",
    "it = iter(ss)\n",
    "for o in range(5):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29518\n",
      "36377\n",
      "2081\n",
      "46279\n",
      "36961\n"
     ]
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "it = iter(ss)\n",
    "for o in range(5):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17751, 9719, 32111, 33890]\n",
      "[8589, 17121, 28658, 24148]\n",
      "[14934, 15977, 13590, 35227]\n",
      "[26552, 816, 3243, 3543]\n",
      "[28352, 42998, 15223, 11538]\n"
     ]
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "it = iter(batchs)\n",
    "for o in range(5):\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "    def __iter__(self):\n",
    "            yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, train_samp)\n",
    "valid_dl = DataLoader(valid_ds, valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08, accuracy: 0.96\n",
      "loss: 0.21, accuracy: 0.94\n",
      "loss: 0.45, accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 2, 1, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 2, 1, 3]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([9, 2]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 3]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([4,5],[6,7])):\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex:\n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(it)\n",
    "xb.shape, yb.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPpWbE9GmhA1uAn+F2QzF+",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
